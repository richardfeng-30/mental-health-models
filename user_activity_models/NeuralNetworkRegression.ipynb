{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d89b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Pandas requires version\")\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456c501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8088eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(''data/csv/user_data.csv'') \n",
    "df.columns\n",
    "removed_cols = ['id', 'hobbies', 'average_positive_probability_before', \n",
    "                'average_positive_probability_after', 'diff','score_change', \n",
    "                'count_id_after','count_id_before','urban_rural','race_ethnicity']\n",
    "df = df.drop(columns=removed_cols)\n",
    "df.shape\n",
    "\n",
    "df = df.apply(pd.to_numeric, errors='coerce')  # Convert all columns to numeric\n",
    "df = df.fillna(df.mean())  # Impute missing values with mean\n",
    "\n",
    "# Define categorical columns\n",
    "categorical_columns = ['gender', 'socio_economic_status', 'parental_involvement']\n",
    "\n",
    "# Convert categorical columns to one-hot encoding\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop(columns=['mental_health_score_after'])\n",
    "y = df['mental_health_score_after']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1abd53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = make_pipeline(StandardScaler(), MLPRegressor(random_state=42, max_iter=500))\n",
    "nn_model.fit(X_train, y_train)\n",
    "y_pred_nn = nn_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "mse_nn = mean_squared_error(y_test, y_pred_nn)\n",
    "print(f'Neural Network MSE: {mse_nn:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9db5d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'NaNs in X_train: {np.isnan(X_train).sum()}')\n",
    "print(f'NaNs in y_train: {np.isnan(y_train).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c6a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79e913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'mlpregressor__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'mlpregressor__activation': ['relu', 'tanh'],\n",
    "    'mlpregressor__solver': ['adam', 'sgd'],\n",
    "    'mlpregressor__alpha': [0.001, 0.01, 0.1],\n",
    "    'mlpregressor__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'mlpregressor__learning_rate_init': uniform(0.001, 0.1),\n",
    "    'mlpregressor__max_iter': [200, 300, 400],\n",
    "    'mlpregressor__early_stopping': [True, False]\n",
    "}\n",
    "param_dist = {\n",
    "    'mlpregressor__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'mlpregressor__activation': ['relu', 'tanh'],\n",
    "    'mlpregressor__solver': ['adam', 'sgd'],  # Exclude 'sgd' for robustness\n",
    "    'mlpregressor__alpha': [0.001, 0.01, 0.1],\n",
    "    'mlpregressor__learning_rate': ['constant', 'adaptive'],\n",
    "    'mlpregressor__learning_rate_init': uniform(0.001, 0.01),  # Reduced range\n",
    "    'mlpregressor__max_iter': [200, 300],\n",
    "    'mlpregressor__early_stopping': [True, False]\n",
    "}\n",
    "# Initialize MLPRegressor within a pipeline (optional but recommended for scaling)\n",
    "mlp_model = make_pipeline(StandardScaler(), MLPRegressor(random_state=42))\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=mlp_model,\n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=300,  # Number of parameter settings that are sampled\n",
    "                                   scoring='neg_mean_squared_error',  # Use a suitable metric for your problem\n",
    "                                   cv=5,  # Number of cross-validation folds\n",
    "                                   verbose=2,  # Higher verbosity to see more details\n",
    "                                   n_jobs=-1,  # Use all available cores\n",
    "                                   random_state=42)\n",
    "\n",
    "# Fit the RandomizedSearchCV to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(f'Best parameters found by RandomizedSearchCV: {best_params}')\n",
    "print(f'Best score (negative MSE): {best_score:.2f}')\n",
    "\n",
    "# Get the best estimator\n",
    "best_mlp = random_search.best_estimator_\n",
    "\n",
    "# Predict using the best estimator\n",
    "y_pred = best_mlp.predict(X_test)\n",
    "\n",
    "# Evaluate tuned model performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Tuned MLPRegressor MSE: {mse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee93b044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd5d14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17115dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test data\n",
    "y_pred = best_mlp.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error and R^2 score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
    "print(f'R-squared (R2): {r2:.2f}')\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef0f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract relevant columns from results DataFrame\n",
    "params = results['params']\n",
    "mean_scores = results['mean_test_score']\n",
    "\n",
    "# Plotting mean scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(params)), mean_scores, align='center')\n",
    "plt.yticks(range(len(params)), params)\n",
    "plt.xlabel('Mean Test Score')\n",
    "plt.title('Mean Test Score of Hyperparameter Combinations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3ff2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the best estimator\n",
    "y_pred = best_mlp.predict(X_test)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Plotting residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='-', linewidth=1)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed47ca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting predicted vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Scatter Plot of Predicted vs Actual Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc19f9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of correlation matrix plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(X_train.corr(), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix of Features')\n",
    "plt.show()\n",
    "\n",
    "# Example of VIF plot\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Feature\"] = X_train.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "print(vif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ddff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the coefficients (weights) of the first layer\n",
    "first_layer_weights = best_mlp.named_steps['mlpregressor'].coefs_[0]\n",
    "\n",
    "# Assuming X_train is your training data\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Plotting the magnitude of weights for each feature in the first layer\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(feature_names)), np.abs(first_layer_weights).mean(axis=1), align='center')\n",
    "plt.yticks(range(len(feature_names)), feature_names)\n",
    "plt.xlabel('Average Magnitude of Weights')\n",
    "plt.title('Feature Importance (Average Magnitude of Weights) in the First Layer')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325d90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Calculate permutation importance\n",
    "perm_importance = permutation_importance(best_mlp, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Sort features by their importance\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "\n",
    "# Plot permutation importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(feature_names)), perm_importance.importances_mean[sorted_idx], align='center')\n",
    "plt.yticks(range(len(feature_names)), np.array(feature_names)[sorted_idx])\n",
    "plt.xlabel('Permutation Importance')\n",
    "plt.title('Feature Importance (Permutation Importance)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55da75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db9631b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
